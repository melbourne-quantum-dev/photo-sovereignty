# config.example.yaml
# Photo Sovereignty Pipeline - Configuration Template
#
# Setup Instructions:
#   1. Copy this file: cp config.example.yaml config.yaml
#   2. Edit config.yaml with your actual paths
#   3. config.yaml is gitignored (keeps your paths private)
#
# v0.1.0 Note: This config file is now OPTIONAL. If not present, the application
# uses platform-appropriate defaults via platformdirs:
#   Linux: ~/.config/photo-pipeline/, ~/.local/share/photo-pipeline/
#   macOS: ~/Library/Application Support/photo-pipeline/
#   Windows: %APPDATA%/photo-pipeline/
#
# Create this file only if you need custom paths different from the defaults.

paths:
  # Input directory containing unorganized photos
  # Default: ~/Pictures (or %USERPROFILE%\Pictures on Windows)
  # Uncomment and customize if needed:
  # input_directory: ~/Pictures/phone_export

  # Output directory for organized photos (creates year subdirectories)
  # Default (Linux): ~/.local/share/photo-pipeline/organized
  # Default (macOS): ~/Library/Application Support/photo-pipeline/organized
  # Default (Windows): %APPDATA%/photo-pipeline/organized
  # Uncomment and customize if needed:
  # output_directory: ~/Pictures/organized

  # SQLite database file path (stores metadata, GPS, object tags, embeddings)
  # Default (Linux): ~/.local/share/photo-pipeline/photo_archive.db
  # Default (macOS): ~/Library/Application Support/photo-pipeline/photo_archive.db
  # Default (Windows): %APPDATA%/photo-pipeline/photo_archive.db
  # Uncomment and customize if needed:
  # database: ~/Pictures/photo_archive.db

  # Cache directory for ML models (YOLO, CLIP, OCR)
  # Default (Linux): ~/.cache/photo-pipeline/models
  # Default (macOS): ~/Library/Caches/photo-pipeline/models
  # Default (Windows): %LOCALAPPDATA%/photo-pipeline/Cache/models
  # Uncomment and customize if needed:
  # model_cache: ~/.cache/photo-pipeline/models

processing:
  # Process subdirectories recursively (useful for multi-part iCloud exports)
  # Options:
  #   true  - Recursively process all subdirectories
  #   false - Only process files in immediate directory (safer)
  # Default: false
  # recursive: false

  # Batch size for ML processing (adjust based on GPU memory)
  # YOLO: 32 works on 12GB VRAM (RTX 3080)
  # CLIP: 64 works on 12GB VRAM
  # Default: 32
  batch_size: 32

  # Confidence threshold for object detection (0.0 to 1.0)
  # Higher = fewer false positives, lower = more detections
  # Default: 0.5
  confidence_threshold: 0.5

  # Filename preservation strategy when organizing photos
  # Options:
  #   'descriptive_only' - Preserve non-camera names (e.g., 'piazza-dei-signori.jpg')
  #                        but strip camera names (e.g., 'IMG_1234.jpg')
  #   true               - Always preserve original filename
  #   false              - Never preserve (timestamp only)
  # Default: 'descriptive_only'
  #
  # Examples:
  #   Camera photo:      2023/2023-06-15_143022.jpg (camera name stripped)
  #   Descriptive photo: 2023/2023-06-15_143022_wedding-reception.jpg (preserved)
  #   Filesystem date:   filesystem_dates/2025-11-23_095802_piazza-dei-signori.jpg
  preserve_filenames: descriptive_only

models:
  # YOLOv11 model variant (yolo11n, yolo11s, yolo11m, yolo11l, yolo11x)
  # Larger = more accurate but slower. yolo11m recommended.
  # Default: yolo11m.pt
  yolo: yolo11m.pt

  # OpenCLIP model architecture
  # ViT-L/14 recommended for best semantic search quality
  # Default: ViT-L-14
  clip: ViT-L-14

  # OpenCLIP pretrained weights
  # laion2b_s32b_b82k = trained on 2B image-text pairs
  # Default: laion2b_s32b_b82k
  clip_pretrained: laion2b_s32b_b82k

  # EasyOCR language codes (add more as needed)
  # Example: ['en', 'es'] for English + Spanish
  # Default: ['en']
  ocr_languages: ["en"]
